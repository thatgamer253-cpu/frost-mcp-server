```python
# PoC for an AI-based web scraping tool using Python
import requests
from bs4 import BeautifulSoup
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans

# Step 1: Define the URL to scrape
url = "https://www.example.com"

# Step 2: Retrieve the web page content
response = requests.get(url)
web_content = response.content

# Step 3: Parse the content with BeautifulSoup
soup = BeautifulSoup(web_content, 'html.parser')

# Step 4: Extract text data from specific HTML tags
text_data = [element.get_text() for element in soup.find_all('p')]

# Step 5: Vectorize the text data using TF-IDF
vectorizer = TfidfVectorizer(stop_words='english')
X = vectorizer.fit_transform(text_data)

# Step 6: Initialize and fit a KMeans clustering model
num_clusters = 5
kmeans = KMeans(n_clusters=num_clusters, random_state=0)
kmeans.fit(X)

# Step 7: Output the clustering results
labels = kmeans.labels_
for idx, label in enumerate(labels):
    print(f'Text Segment {idx} belongs to Cluster {label}')
```