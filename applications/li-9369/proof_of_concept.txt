```python
# Python Script Template for Data Scraping and AI-Powered Processing

# Importing necessary libraries
import requests
from bs4 import BeautifulSoup
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB

# Define a function to scrape LinkedIn job descriptions
def scrape_job_descriptions(url):
    response = requests.get(url)
    soup = BeautifulSoup(response.text, 'html.parser')
    
    # Navigating and extracting job descriptions
    jobs = soup.find_all('div', class_='job-card-container')
    job_descriptions = []
    
    for job in jobs:
        description = job.find('p', class_='job-card-list__description').get_text()
        job_descriptions.append(description)
        
    return job_descriptions

# Function to train a simple AI model on job description data
def train_job_classification_model(job_descriptions, labels):
    # Convert text data into feature vectors
    vectorizer = CountVectorizer(stop_words='english')
    X = vectorizer.fit_transform(job_descriptions)
    
    # Fit a Naive Bayes model for classification
    model = MultinomialNB()
    model.fit(X, labels)
    
    return model, vectorizer

# Example job link
job_url = 'https://www.linkedin.com/jobs/search/?keywords=ai%20engineer'

# Scrape job descriptions from the URL
job_descriptions = scrape_job_descriptions(job_url)

# Dummy labels for training purposes (in practice, these would be real categories)
labels = ['Tech', 'Non-Tech'] * (len(job_descriptions) // 2) # Example label distribution

# Train the job classification model
model, vectorizer = train_job_classification_model(job_descriptions, labels)

# Note: This script provides a template to be expanded upon with real data and labels.
```